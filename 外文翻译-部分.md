# 大型系统软件 部分故障的理解、检测与定位

本文收录在第 17 届 USENIX 网络系统设计与实施研讨会论文集 (NSDI ’20) 中

（2020 年 2 月 25 日至 27 日 • 美国加利福尼亚州圣克拉拉）

开源获取会议记录：第十七届USENIX网络研讨会系统设计与实施（NSDI '20）（NetApp赞助）

作者：Chang Lou ，Peng Huang，Scott Smith（约翰霍普金斯大学）



## 摘要 

云系统中经常发生部分故障，并可能产生严重的危害，包括不一致和数据丢失。不幸的是，这些故障并没有被很好地理解，也不能进行有效地检测。在本文中，我们首先研究了来自五个成熟系统的100个真实部分故障，以理解它们的特征。我们发现这些故障是由触发生产环境特有条件的各种缺陷引起的。手动编写有效的检测器来系统地检测此类故障既耗时又容易出错。因此，我们提出了 OmegaGen，这是一种静态分析工具，它通过使用新颖的程序缩减技术为给定程序自动生成定制的看门狗。我们已经成功地将 OmegaGen 应用于六个大型分布式系统。在评估这些系统中的 22 个实际部分故障案例时，生成的看门狗可以检测 20 个案例，中位检测时间为 4.2 秒，并确定 18 个案例的故障范围。生成的看门狗还在最新版本的 ZooKeeper 中揭秘了一个未知的、常见的部分故障错误。

 

## 1. 引言 

构建永不失误的大型软件是难以把握的。因此，健壮系统的设计人员必须设计运行机制，以主动检查程序是否仍在正常运行，如果没有则作出回应。许多这些机制都是基于一个简单的假设，即程序会由于死机、中断或网络断开而完全停止。

 

然而，这个假设并没有反映现代云基础设施中表现出的复杂故障原因。一个典型的云软件程序由数十个模块、数百个动态线程和数万个函数组成，用于处理不同的请求、运行各种后台任务、应用层优化等。毫不奇怪，实际中这样的程序会经历部分故障，即 其中一些而不是全部功能被破坏。例如，对于现代分布式文件系统中的数据节点进程，当该进程中的重新平衡器线程不能再将非平衡块分配给其他远程数据节点进程时，即使该进程仍然存在，也可能会发生部分故障。或者，此数据节点进程中的块接收器守护进程静默退出，因而块不再持续地保存到磁盘。这些部分故障是运营商不容忽略的潜在问题；它们可能会造成严重损害，包括不一致、“僵尸”行为和数据丢失。事实上，部分故障是许多灾难性现实中断发生的原因 [1, 17, 39, 51, 52, 55, 66, 85, 86]。例如，Microsoft Office 365 邮件服务遭受了 8 小时的中断，而这是因为邮件服务器的反病毒引擎模块在识别一些可疑邮件时卡住了 [39]。

 

当发生部分故障时，通常需要很长时间才能检测到事故。相比之下，可以通过现有机制 快速识别、重新启动或修复 遭受完全故障的过程，从而降低故障影响。更糟糕的是，部分故障会导致难以调试的神秘症状 [78]，例如，create() 请求超时但 write() 请求仍然有效。在由于引导部分失败而导致产生 ZooKeeper 中断 [86] 时，即使在触发警报之后，引导日志也几乎没有关于 问题出在哪儿 的线索。开发人员花费了大量时间来定位问题引导进程中的故障（图 1）。在查明故障之前，简单重启引导进程没有效果（因为相同症状很快又出现）。

<img src="https://gitee.com/DLW1941/img_bed/raw/master/imgs/202203142337925.png" alt="image-20220314233735865" style="zoom: 50%;" />

图 1：由于部分故障导致 ZooKeeper 中断 [86]



从业者和研究界都呼吁关注这一缺漏。例如，Cassandra 开发人员采用了更先进的应计故障检测器 [73]，但仍然得出结论，其当前设计“几乎没有能力有效地采取重要措施来处理部分故障”[13]。 Prabhakaran 等人分析了特定磁盘的部分故障 [88]。Huang 等人讨论了云基础设施中的灰色故障 [76] 挑战。然而，软件部分故障的总体特征还没有被很好地理解。

 

在本文中，我们首先试图回答这个问题，部分故障在现代系统中是如何表现的？为了阐明这一点，我们对来自五个大型开源系统的 100 个现实部分故障案例进行了研究（第 2 节）。我们发现，有近一半 (48%) 研究的故障会导致某些特定的软件功能被卡住。此外，所研究的大多数故障（71%）是由生产环境中的特有条件触发的，例如错误的输入、调度、资源争用、易碎磁盘或有故障的远程进程。由于这些故障会影响压缩和持久性等内部特性，因此外部检测器或探测器可能无法观察到它们。

​        

 如何在运行时系统地检测和定位部分故障？从业者目前依赖于运行临时健康检查（例如，每隔几秒发送一次 HTTP 请求并检查其响应状态 [3, 42]）。但是这样的健康检查太浅了，无法暴露大范围的故障。该领域最先进的研究工作是 Panorama [75]，它将目标流程的各种请求者转换为观察者，以报告该流程的灰色故障。这种方法受到请求者从外部观察到内容的限制。此外，这些观察者无法定位故障进程中检测到的故障。

 

我们提出了一种新方法，通过减少程序来构建有效部分故障检测器。给定一个程序 P，我们的基本思想是从 P 派生一个简化但具有代表性的版本 W 作为检测器模块，并在生产中定期测试 W 以暴露 P 中的各种潜在故障。我们称 W 为内在看门狗。这种方法有两个主要好处：首先，由于看门狗源自主程序并“模仿”主程序，相比现有的无状态运行、浅层健康检查或外部观察者，它可以更准确地反映主程序的状态。其次，简化版本使得看门狗简明并有助于定位故障。

 

对于开发人员来说，在大型软件上手动应用缩减方法既耗时又容易出错。为了减轻这个负担，我们设计了一个工具，OmegaGen，它可以静态分析给定程序的源代码，并为目标程序生成定制的内在看门狗。

 

我们在 OmegaGen 中实现程序缩减的出发点 源自于W 的目标仅仅是检测和定位运行时错误；因此，它不需要重新创建 P 业务逻辑的全部细节。例如，如果 P 在紧密循环中调用 write()，出于检查目的，带有一个 write() 的 W 可能足以暴露错误。此外，虽然检查各种故障很诱人，但鉴于资源有限，W 应该专注于检查仅在生产环境中出现的故障。确定性地导致错误结果的逻辑错误（例如，不正确的排序）应是离线单元测试的重点。以图 1 为例。在检查 SyncRequestProcessor 时，W 不需要检查函数 serializeNode 中的大部分指令，例如，第 3-6 行和第 8 行。虽然这些指令在生产中失败的可能性很小，但反复检查它们会为有限的资源预算产生递减收益。

 

一般来说，准确区分逻辑确定性故障和生产相关故障是很困难的。 OmegaGen 使用启发式方法来分析指令的“脆弱性”程度，基于指令是否执行某些 I/O、资源分配、异步等待等。因此，由于图 1 的第 9 行执行写入，因此在 W 中将被评估为易受攻击并经过测试。期望 W 总是包含故障根本原因指令是不现实的。幸运的是，一个大致的评估通常就足够了。例如，即使我们只评估整个 serializeNode 函数或其调用者存在的漏洞，并在 W 中定期对其进行测试，W 仍然可以检测到这个部分故障。

 

一旦选择了易受攻击的指令，OmegaGen 会将它们封装到检查器中。 OmegaGen 的第二个贡献是提供了几个强大的隔离机制，因此看门狗检查器不会干扰主程序。对于内存隔离，OmegaGen 识别检查器的上下文，并在主程序中生成带有钩子的上下文管理器，在检查器中使用它们之前复制上下文。 OmegaGen 通过重定向消除 I/O 操作的副作用，并设计了一个幂等包装机制来安全地测试 非幂等操作。

 

我们已将 OmegaGen 应用于六个大型（28K 至 728K SLOC）系统。 OmegaGen 自动为这些系统生成数十到数百个看门狗检查器。为了评估生成看门狗的有效性，我们重现了 22 个现实部分故障。我们的看门狗可以检测到 20 个案例，中位检测时间为 4.2 秒，并定位了 18 个案例的故障范围。相比之下，最好的手动编写的基线检测器只能检测 11 个案例并定位 8 个案例。通过测试，我们的看门狗在最新的 ZooKeeper 中揭秘了一个新的、惯常的部分故障错误。

 

## 2. 理解局部故障

部分故障是一个众所周知的问题。 Gupta 和 Shute 报告称，在 Google Ads 基础架构中，部分故障比完全故障更常见 [70]。研究人员研究了部分磁盘故障 [88] 和慢速硬件故障 [68]。但是软件是如何部分故障的还不是很清楚。在本节中，我们研究真实的部分故障，以深入理解这个问题并指导我们设计解决方案。

 

**范围** 我们关注过程粒度上的部分故障。这个过程可以是独立的，也可以是大型服务中的一个组件（例如，存储服务中的数据节点）。我们研究的部分故障是关于偏离它本身应提供功能的流程，例如，存储和平衡数据块，无论它是服务组件还是独立服务器。我们注意到，用户可能会在服务粒度上定义部分故障（例如，Google 驱动器变更为只读），其根本原因可能是某些组件崩溃或部分故障。

<img src="https://gitee.com/DLW1941/img_bed/raw/master/imgs/202203150006039.png" alt="image-20220315000623939" style="zoom:50%;" />

表 1：研究的软件系统部分故障案例以及这些案例涵盖的唯一版本、版本和日期范围。

<img src="https://gitee.com/DLW1941/img_bed/raw/master/imgs/202203150007476.png" alt="image-20220315000731403" style="zoom:50%;" />

图 2：故障的根本原因分布。 UE：未捕获的错误； IB：无限期阻塞； EH：错误的错误处理； DD：死锁； PB：性能错误； LE：逻辑错误； IL：无限循环； RL：资源泄漏。



**方法** 我们研究了五个广泛使用的大型软件系统（表 1）。它们提供不同服务 并用不同语言编写。为了收集研究案例，我们首先在官方错误跟踪器中抓取所有标记为关键优先级的错误单。然后，我们从测试中过滤单并随机抽取剩余的故障单。为了最大限度地减少我们研究的部分故障类型的偏差，我们详尽地检查了每个抽样案例并手动确定它是否是完全故障（例如，崩溃），如果是，则丢弃。我们总共收集了 100 个故障案例（每个系统 20 个案例）。

 

### 2.1 发现

**发现 1**：在所有的五个系统中，部分故障一直出现在整个发布历史中（表 1）。其中 54%发生在最近三年的软件版本中。

出现这种趋势，部分原因是 随着软件的发展，添加了新功能和性能优化，这使故障原因复杂化。例如，HDFS 在 0.23 版本中引入了短路本地读取功能 [30]。为了实现此功能，添加了一个 DomainSocketWatcher，它监视一组 Unix 域套接字并在它们变得可读时调用回调。但是这个新模块可能会意外退出进程并导致执行短路读取的应用程序挂起 [29]。

 

**发现 2**：研究故障的根本原因是多种多样的。前三种（总共 48%）根本原因类型是未捕获的错误、无限期阻塞和错误的故障处理（图 2）。

 未捕获的错误是指某些操作触发了一些软件不期望的错误条件。例如，当流读取器遇到诸如 RuntimeException [6] 之类的 IOException 以外的错误时，Cassandra 中的流会话可能会挂起。当某些函数调用被永远阻塞时，就会发生无限阻塞。在一种情况下 [27]，备用 HDFS 名称节点中的 EditLogTailer 向活动名称节点发出 RPC rollEdits()；但是当活动的namenode被冻结但没有崩溃时，这个调用被阻止了，这阻止了备用节点的激活。 Buggy 错误处理包括静默吞咽错误、空处理程序 [93]、过早继续等。其他常见的根本原因包括死锁、性能错误、无限循环和逻辑错误。

 

**发现 3**：近一半 (48%) 的部分故障导致某些功能卡住。

 图 3 显示了研究的故障后果。请注意，这些故障都是局部的。对于“卡住”的故障，某些软件模块（如套接字观察程序）没有取得任何进展；但该进程并非完全无响应，即其核心模块仍能及时响应，它还可以处理其他请求，例如非本地读取。

 除了“卡住”的情况外，17% 的部分故障会导致某些操作需要很长时间才能完成（图 3 中的“慢”类型）。这些缓慢故障不仅导致了可选优化的低效率。更进一步，它们是严重的性能错误，导致受影响的功能几乎无法使用。在一个案例 [5] 中，将 Cassandra 2.0.15 升级到 2.1.9 后，用户发现生产集群的读取延迟从 6 ms/op 增加到 100 ms/op 以上。

<img src="https://gitee.com/DLW1941/img_bed/raw/master/imgs/202203150017139.png" alt="image-20220315001730019" style="zoom:50%;" />

图 3：所研究的故障后果。

 

**发现 4**：在 13% 的研究案例中，模块变成了具有未定义故障语义的“僵尸”。

 这通常发生在故障模块意外退出其正常控制循环 或 即使遇到一些无法容忍的严重错误时仍继续执行。例如，意外的异常导致 ZooKeeper 侦听器模块意外退出其 while 循环，因此新节点无法再加入集群 [46]。在另一种情况下，即使块池未能初始化 [26]，HDFS 数据节点也会继续运行，这将在尝试进行块报告时触发 NullPointerException。

 

**发现 5**：15% 的部分故障是无声的（包括数据丢失、损坏、不一致和错误结果）。

 如果没有详细的正确规范，它们通常很难检测到。例如，当 Mesos 代理垃圾收集旧的从属沙箱时，它可能会错误地清除持久卷数据 [37]。在另一种情况 [38] 中，Apache Web 服务器会“失控”，例如，对 .js 文件的请求会收到 image/png 的响应，因为在出现错误时，后端连接不能正确关闭。

 

**发现 6**：71% 的故障是由某些特定的环境条件、输入或其他进程中的故障触发的。

例如，ZooKeeper 中的部分故障只能在记录的长度字段中出现某些损坏消息时触发 [66]。 ZooKeeper 领导者的另一个部分故障只会在连接的追随者挂起时发生 [50]，这会阻止其他追随者加入集群。这些部分故障很难通过生产前测试暴露出来，并且需要在运行时检测的机制。此外，如果运行时检测器使用不同的设置或检查输入，它可能无法检测到此类故障。

 

**发现 7**：大多数 (68%) 的故障是“粘性的”。

 粘性意味着进程不会自行从故障中恢复。故障进程需要重新启动或修复才能再次运行。在一种情况下，竞争条件导致了意外的 RejectedExecutionException，这导致 RPC 服务器线程静默退出其循环并停止侦听连接 [9]，必须重新启动此线程才能解决此问题。对于某些故障，需要一些额外的修复操作，例如修复文件系统不一致 [25]。

 其余（32%）的故障是“暂时的”，即故障模块可能在某些条件变化后恢复，例如，当冻结的名称节点变得可响应时 [27]。然而，到那时，这些非粘性故障已经造成了很长一段时间的损坏（一种情况下为 15 分钟 [45]）。

 

**发现 8**：中位诊断时间为 6 天零 5 小时。

 例如，诊断 Cassandra 故障 [10] 花了开发人员将近两天的时间。结果发现根本原因相对简单：MeteredFlusher 模块被阻塞了几分钟并影响了其他任务。尽管根本原因很简单，但诊断时间长的一个常见原因是故障 令人困惑的症状，因而误导了诊断方向。另一个常见的原因是故障进程中运行时信息暴露不足。用户必须启用调试日志、分析堆、和/或 来检测代码，以识别产生故障期间发生的情况。

 

### 2.2 影响 

总体而言，我们的研究表明，部分故障是大型软件系统中常见且影响严重的问题。大多数研究的故障都与生产相关（发现 6 个），这需要运行时机制来检测。此外，如果运行时检测器除了检测之外还可以定位故障，它将降低离线诊断的难度（发现 8）。现有的检测器，如心跳、探测器 [69] 或观察者 [75] 是无效的，因为它们几乎不会暴露在流程内部受影响的功能中（例如，压缩）。

 

人们可能会得出结论，开发人员有责任在他们的代码中添加有效的运行时检查，例如在上述 HDFS 故障 [27] 中对 rollEdits() 操作进行计时器检查。然而，仅仅依靠开发人员预测并为每个操作添加防御性检查是不现实的。我们需要一种系统的方法来帮助开发人员构建特定于软件的运行时检查器。

 

完全自动化定制运行时检查器的构建是可取的，但考虑到部分故障的多样性（发现 2），这在一般情况下是极其困难的。事实上，15% 研究的故障是静默的，这需要详细的正确性规范才能捕获。幸运的是，我们研究中的大多数故障都违反了活跃度（发现 3）或在某些程序点触发了显式错误，这表明检测器可以在没有深入语义理解的情况下自动构建。

 

## 3 . 使用看门狗捕获 部分故障

 

我们考虑一个由许多较小模块组成的大型服务器进程π，它能提供一系列功能R（如，请求侦听器、快照管理器、缓存管理器等的数据节点服务器等）。而这需要一个故障检测器来监控高可用性的过程。针对部分故障，我们专门将过程 π 中的部分故障定义为 不会导致 π 崩溃但会使某些功能 R f ( R 的安全性或活性）违规或严重缓慢的故障。除了检测故障外，我们的目标是定位过程中的故障，便于后续的故障排除和解决。

 

在我们的研究指导下，我们提出了一个设计有效部分故障检测器的交叉原则——构建与受监控过程的执行相交叉的定制检查。基本原理是部分故障通常涉及特定的软件功能和不良状态；为了暴露此类故障，检测器需要使用精心挑选的有效载荷来运行特定的代码区域。现有检测器（包括心跳和 HTTP 测试）中的检查过于通用，并且与被监控进程的状态和执行脱节。

 

我们提倡遵循上述原则的内在看门狗设计（图 4）。内在看门狗是进程的专用监控扩展。此扩展定期执行一组针对不同模块量身定制的检查器。看门狗驱动程序管理检查程序的调度和执行，并可选择应用恢复操作。检测的关键目标是让看门狗遇到与主程序类似的故障。这是通过 (a) 执行模仿式检查器 (b) 使用有状态的有效负载 (c) 共享受监视进程的执行环境来实现的。

 

